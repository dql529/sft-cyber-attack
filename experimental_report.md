# 初步实验报告：基于大型语言模型进行网络入侵检测的可行性研究

**日期**: 2025年8月14日
**版本**: 7.0

## 1. 研究目标

本研究旨在探索利用大型语言模型（LLM）完成网络入侵检测（IDS）任务的可行性。核心目标是评估LLM在不同情景下（零样本、少样本、微调）的性能，并与传统机器学习方法进行对比，以期找到一种数据高效、快速响应的新范式。

## 2. 实验设置

- **数据集**: UNSW-NB15 (经过预处理和筛选)。
- **核心方法**: 将表格化的网络流量数据，通过**语义化Prompt工程**，转化为自然语言描述，以供LLM处理。
- **评估方案**:
    - **零样本 (Zero-Shot)**: 不提供任何示例，直接测试模型能力。
    - **少样本 (Few-Shot)**: 在上下文中提供1个或5个示例，测试模型的快速学习能力。
    - **微调 (Fine-Tuning)**: 使用LoRA技术对模型进行参数高效微调。
- **评估指标**: F1-Score (宏平均和加权平均), Precision, Recall。

## 3. 已完成的实验阶段与发现

### 阶段一：使用代码专用模型 (`DeepSeek-Coder-6.7B`) 的探索

**结论**: `DeepSeek-Coder`作为一个代码专用模型，其基础能力和知识结构使其无法“泛化”和“理解”网络流量分类任务，最终在所有评估场景下**F1分数均为0.00**。该模型的选型被证明是**不适用**的。（详细调试过程见附录）

### 阶段二：战略转向通用模型 (`gemma-3-270m`)

- **动机**: 鉴于代码专用模型的失败，我们将策略调整为使用更小、更通用的对话/推理模型。
- **实验2.1: 少样本能力验证**
    - **观察**: 与`DeepSeek-Coder`的表现形成鲜明对比，`gemma-3-270m`模型在少样本学习上取得了巨大成功，证明了此方法论配合正确模型是有效的。
    - **数据**: 
        - **Zero-Shot**: 加权平均F1分数为 **0.00**。
        - **1-Shot**: 加权平均F1分数从0跃升到了 **0.31**。
        - **5-Shot**: 加权平均F1分数达到了 **0.35**。
    - **结论**: **这无可辩驳地证明了我们的核心假设**：选择一个合适的通用大模型，配合我们的语义化Prompt方法，能够通过极少量的数据就爆发出惊人的学习能力。

- **实验2.2: 初步微调（200步）的意外发现**
    - **观察**: 经过200步的初步微调后，模型的评估性能反而**再次归零**。
    - **分析**: 这强烈地暗示，**短时间的微调，可能反而会“扰乱”大模型原本的、通用的指令遵循能力**，使其学习到一个错误或过于复杂的行为模式（如生成描述性文本而非标签）。这本身就是一个非常有价值的、可以写入论文的发现。

## 4. 当前与未来计划

- **当前**: 我们将通过一个专门的评估脚本，深入分析初步微调后的`gemma`模型的输出，以判断模型是被“损坏”了，还是仅仅“学歪了”。
- **下一步 (计划中):**
    - **完整微调**: 基于对初步微调结果的分析，进行完整的、长周期的微调，以期将模型“掰回正轨”，获得最终的、高性能的分类器。
    - **基线对比**: 运行传统机器学习模型（随机森林）和经典的Encoder模型（BERT），作为最终的性能参照基线。

---

## 附录：详细试验与调试记录

本附录记录了为达成上述结论所经历的关键调试与决策过程，体现了研究工作的严谨性。

- **记录1：初步零分问题定位**: 发现模型误解任务（识别协议而非攻击），且答案解析逻辑过于严格。
- **记录2：路径依赖问题 (`FileNotFoundError`)**: 通过动态转换绝对路径增强了代码健壮性。
- **记录3：模型不兼容问题 (`TritonMissing` Error)**: 通过在脚本顶部设置环境变量，解决了在Windows上的环境兼容性问题。
- **记录4：`DeepSeek-Coder`模型能力上限的最终确认**: 结合训练loss下降但验证性能为零的现象，得出模型“严重过拟合”且不适合本任务的结论。
- **记录5：标签映射逻辑错误**: 修正了评估脚本中因字典键值错误导致的计分失败问题。