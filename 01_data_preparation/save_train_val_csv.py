import pandas as pd
import os
import sys
from sklearn.model_selection import train_test_split

# --- è·¯å¾„é…ç½® ---
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)
from config import FILTERED_DATA_CSV, PROMPT_TRAIN_CSV, PROMPT_VAL_CSV, LABEL_MAP


def resolve_path(path_str):
    if isinstance(path_str, str) and path_str.startswith("./"):
        return os.path.join(project_root, path_str)
    return path_str


FILTERED_DATA_CSV = resolve_path(FILTERED_DATA_CSV)
PROMPT_TRAIN_CSV = resolve_path(PROMPT_TRAIN_CSV)
PROMPT_VAL_CSV = resolve_path(PROMPT_VAL_CSV)
# --- è·¯å¾„é…ç½®ç»“æŸ ---

df = pd.read_csv(FILTERED_DATA_CSV)

print("ğŸ”§ Engineering new semantic features from numerical data...")
# ==============================================================================
# === ä¿®æ”¹ 1: åœ¨åˆ—è¡¨ä¸­åŠ å…¥ sload, dload, tcprtt ===
cols_to_categorize = [
    "sbytes",
    "dbytes",
    "spkts",
    "dpkts",
    "dur",
    "sload",
    "dload",
    "tcprtt",
]
# ==============================================================================

labels = ["low", "medium", "high", "very_high"]
for col in cols_to_categorize:
    non_zero_data = df[df[col] > 0][col]
    if not non_zero_data.empty:
        try:
            # ä½¿ç”¨ qcut è¿›è¡Œåˆ†ç®±
            quantiles, bins = pd.qcut(
                non_zero_data,
                q=len(labels),
                labels=labels,
                retbins=True,
                duplicates="drop",
            )
            # åº”ç”¨åˆ†ç®±åˆ°æ•´ä¸ªåˆ—
            df[f"{col}_cat"] = pd.cut(
                df[col], bins=bins, labels=labels, include_lowest=True
            )
            # å°†0å€¼å’ŒNaNå€¼å¤„ç†ä¸º 'zero' ç±»åˆ«
            df[f"{col}_cat"] = (
                df[f"{col}_cat"].cat.add_categories("zero").fillna("zero")
            )
            print(f"  - Categorized '{col}' into semantic bins.")
        except Exception as e:
            print(
                f"  - Could not categorize '{col}': {e}. Using raw values as fallback."
            )
            df[f"{col}_cat"] = df[col]
    else:
        df[f"{col}_cat"] = "zero"
        print(f"  - Column '{col}' contains only zeros.")

label2id = {v: k for k, v in LABEL_MAP.items()}
df["attack_cat"] = df["attack_cat"].str.strip()
# è½¬æ¢labelåˆ—ï¼Œå¹¶å¤„ç†æ— æ³•æ˜ å°„çš„æƒ…å†µ
df["label"] = df["attack_cat"].map(label2id)
num_null_labels = df["label"].isnull().sum()
if num_null_labels > 0:
    print(f"  - è­¦å‘Šï¼šä¸¢å¼ƒ {num_null_labels} è¡Œæ— æ³•æ˜ å°„æ”»å‡»ç±»åˆ«çš„æ•°æ®ã€‚")
    df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)


# ==============================================================================
# === ä¿®æ”¹ 2: å‡çº§ build_prompt å‡½æ•° ===
def build_prompt(row):
    """
    æ„å»ºä¸€ä¸ªç»“æ„åŒ–ã€å¸¦ç¤ºä¾‹çš„æç¤ºï¼Œä»¥å¼ºåˆ¶æ¨¡å‹æŒ‰å›ºå®šæ ¼å¼è¾“å‡ºã€‚
    (æ–°ç‰ˆï¼šåŒ…å«æ›´å¤šç‰¹å¾å’Œé€»è¾‘åˆ¤æ–­)
    """
    class_labels = "[Backdoor, DoS, Exploits, Normal, Reconnaissance, Shellcode, Worms]"

    # ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ¥åŠ¨æ€æ„å»ºæè¿°ï¼Œæ›´çµæ´»ã€æ›´æ¸…æ™°
    description_parts = [
        f"A {row['proto']} connection with {row['state']} state had a {row['dur_cat']} duration."
    ]

    # æ™ºèƒ½å¤„ç† 'service' å­—æ®µ
    if row['service'] != '-' and pd.notna(row['service']):
        description_parts.append(f"The connection service was identified as {row['service']}.")
    else:
        description_parts.append("The connection service was not specified.")

    # æ·»åŠ æ•°æ®åŒ…ä¿¡æ¯
    description_parts.append(
        f"It involved {row['spkts_cat']} source packets (total size: {row['sbytes_cat']}) "
        f"and {row['dpkts_cat']} destination packets (total size: {row['dbytes_cat']})."
    )

    # æ·»åŠ è´Ÿè½½ï¼ˆé€Ÿç‡ï¼‰ä¿¡æ¯
    description_parts.append(
        f"The source load was {row['sload_cat']} and the destination load was {row['dload_cat']}."
    )

    # ä»…å½“åè®®æ˜¯ tcp ä¸” tcprtt > 0 æ—¶ï¼Œæ‰æ·»åŠ  TCP RTT ä¿¡æ¯
    if row['proto'] == 'tcp' and row['tcprtt'] > 0:
        description_parts.append(f"The TCP round-trip time was {row['tcprtt_cat']}.")

    # æ·»åŠ å†å²è®¿é—®ä¿¡æ¯ï¼Œå¹¶å¾®è°ƒæªè¾
    description_parts.append(f"The source has connected to this same service {row['ct_srv_src']} times before.")

    # å°†æ‰€æœ‰æè¿°éƒ¨åˆ†ç”¨ç©ºæ ¼è¿æ¥æˆä¸€ä¸ªå®Œæ•´çš„å­—ç¬¦ä¸²
    traffic_description = " ".join(description_parts)

    # ä½¿ç”¨ä¸‰é‡å¼•å·æ„å»ºä¸€ä¸ªæ¸…æ™°ã€å¤šè¡Œçš„ f-string æ¨¡æ¿
    prompt = f'''You are an expert cybersecurity analyst. Your task is to classify network 
      traffic into ONE of the following categories: {class_labels}.

   Follow these rules strictly:
   1. Analyze the traffic description.
   2. Your response MUST be ONLY the category name.
   3. Do not add any explanation, punctuation, or other text.

   ---
   [Example]
   Input: A tcp connection with FIN state had a normal duration. It involved low source packets
      (total size: low) and zero destination packets (total size: zero). The source previously accessed
      the service 1 times.
   Answer: Normal
   ---
   [Task]
   Input: {traffic_description}
   Answer:'''

    return prompt
# ==============================================================================


df["text"] = df.apply(build_prompt, axis=1)

train_df, val_df = train_test_split(
    df[["text", "label"]], test_size=0.2, random_state=42, stratify=df["label"]
)

os.makedirs(os.path.dirname(PROMPT_TRAIN_CSV), exist_ok=True)
train_df.to_csv(PROMPT_TRAIN_CSV, index=False)
val_df.to_csv(PROMPT_VAL_CSV, index=False)

print("ä¿å­˜æ–°çš„ã€ä¿¡æ¯æ›´ä¸°å¯Œçš„è¯­ä¹‰åŒ–Prompt CSVæ–‡ä»¶ï¼š")
print(f"- {PROMPT_TRAIN_CSV}")
print(f"- {PROMPT_VAL_CSV}")

# æ‰“å°ä¸€ä¸ªæ ·æœ¬ä»¥ä¾›æ£€æŸ¥
print("\n--- ç”Ÿæˆçš„Promptæ ·æœ¬ ---")
print(train_df.iloc[0]['text'])
print("--------------------------")